# -*- coding: utf-8 -*-
"""Proyjek Akhir ML-Terapan Sistem Rekomendasi

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SmORLA-yNe6YtyLdidjqZTZaF3dYFJ3I

# Import Library
"""

# Import library
import pandas as pd
import numpy as np
from zipfile import ZipFile
import tensorflow as tf_lib
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split

"""# Load Dataset"""

chess = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/Projek Akhir Machine Learning Terapan /datasets/games.csv")

chess.head()

# Visualisasi distribusi rating
plt.figure(figsize=(10, 6))
sns.histplot(chess['white_rating'], bins=50, kde=True, color='blue', label='White Rating')
sns.histplot(chess['black_rating'], bins=50, kde=True, color='red', label='Black Rating')
plt.title('Distribusi Rating Pemain Putih dan Hitam')
plt.xlabel('Rating')
plt.ylabel('Frekuensi')
plt.legend()
plt.show()

"""# EDA"""

chess.info()

print("Banyaknya permainan: ", len(chess.id.unique()))
print("Banyaknya pemain putih: ", len(chess.white_id.unique()))
print("Banyaknya pemain hitam: ", len(chess.black_id.unique()))
print("Banyaknya opening: ", len(chess.opening_name.unique()))

# Mengecek statistik data
chess.describe()

# Mengecek apakah ada missing values
chess.isnull().sum()

# mengecek apakah ada yang duplicate
chess['id'].duplicated().sum()

# Menemukan baris yang duplikat berdasarkan kolom 'id'
duplikat = chess[chess.duplicated(subset=['id'])]
print(duplikat)

# Mennghapus data permainan yang sama
chess = chess.drop_duplicates(subset=['id'])
chess.info()

chess = (
    chess.assign(
        opening_archetype=chess.opening_name.map(
            lambda n: n.split(":")[0].split("|")[0].split("#")[0].strip()
        ),
        opening_moves=chess.apply(lambda srs: srs['moves'].split(" ")[:srs['opening_ply']],
                                  axis=1)
    )
)

"""Melihat peermainan yang dimainkan oleh satu pemain setidaknya minimal 2 kali"""

chess_played = pd.concat([chess['white_id'], chess['black_id']]).value_counts()
chess_played.reset_index(drop=True).plot.line(figsize=(16, 8), fontsize=18)

n_ge_2 = len(chess_played[chess_played > 1])
print(str(n_ge_2) + " pemain yang bermain catur setidaknya dua kali.")

import matplotlib.pyplot as plt
plt.axvline(n_ge_2, color='green')

len(chess_played)

chess_played[chess_played > 1].sum()

opening_used = (
    pd.concat([
        chess.groupby('white_id')['opening_archetype'].value_counts(),
        chess.groupby('black_id')['opening_archetype'].value_counts()
    ])
    .rename_axis(index=['player_id', 'opening_archetype'])  # Ganti nama indeks dengan list-like
    .reset_index(name='times_used')  # Reset indeks dan beri nama kolom hasil value_counts
    .groupby(['player_id', 'opening_archetype'])['times_used'].sum()  # Jumlahkan times_used
    .reset_index()  # Reset indeks untuk hasil akhir
)

opening_used.head(10)

result = (
    opening_used
    .reset_index()  # Reset indeks untuk memudahkan manipulasi
    .groupby('opening_archetype')  # Kelompokkan berdasarkan opening_archetype
    .times_used
    .sum()  # Jumlahkan times_used
    .sort_values(ascending=False)  # Urutkan secara menurun
    .to_frame()  # Ubah menjadi DataFrame
    .pipe(lambda df: df.assign(times_used=df.times_used / df.times_used.sum()))  # Hitung proporsi
    .squeeze()  # Ubah menjadi Series
    .head(10)  # Ambil 10 teratas
)

print(result)

# Visualisasi distribusi opening archetype
plt.figure(figsize=(12, 8))
chess['opening_archetype'].value_counts().head(20).plot(kind='bar', color='skyblue')
plt.title('Top 20 Opening Archetype')
plt.xlabel('Opening Archetype')
plt.ylabel('Frekuensi')
plt.show()

"""# Data Preprocessing

## Filter by rating range
"""

chess_rating = (
    ((chess['white_rating'] >= 1500) & (chess['black_rating'] <= 2200)) &
    ((chess['black_rating'] >= 1500) & (chess['white_rating'] <= 2200))
)
chess_data = chess[chess_rating].copy()
chess_data.head()

# Visualisasi distribusi rating setelah filter
plt.figure(figsize=(10, 6))
sns.histplot(chess_data['white_rating'], bins=50, kde=True, color='blue', label='White Rating')
sns.histplot(chess_data['black_rating'], bins=50, kde=True, color='red', label='Black Rating')
plt.title('Distribusi Rating Pemain Putih dan Hitam (Setelah Filter)')
plt.xlabel('Rating')
plt.ylabel('Frekuensi')
plt.legend()
plt.show()

"""## Feature Selection"""

# Pilih kolom yang berhubungan untuk rekomendasi
chess = chess[['opening_archetype', 'white_rating', 'black_rating', 'winner', 'increment_code']]

"""# Model Development with Content Based Filtering

## TF-ID Vectorizer
"""

# Inisialisasi
tf = TfidfVectorizer()

tf.fit(chess['opening_archetype'])

tf.get_feature_names_out()

# Melakukan fit lalu ditransformasikan ke bentuk matrix
tfidf_matrix = tf.fit_transform(chess['opening_archetype'])

# Melihat ukuran matrix tfidf
tfidf_matrix.shape

# Mengubah vektor tf-idf dalam bentuk matriks dengan fungsi todense()
tfidf_matrix.todense()

"""## Cosine Similarity"""

# Compute cosine similarity
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim_df = pd.DataFrame(cosine_sim, index=chess['opening_archetype'], columns=chess['opening_archetype'])
cosine_sim_df

cosine_sim_df = pd.DataFrame(cosine_sim, index=chess['opening_archetype'], columns=chess['opening_archetype'])
print('Shape:', cosine_sim_df.shape)

# Melihat similarity matrix pada setiap resto
cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

# Visualisasi matriks cosine similarity
plt.figure(figsize=(12, 8))
sns.heatmap(cosine_sim_df.iloc[:10, :10], cmap='viridis', annot=True)
plt.title('Matriks Cosine Similarity (10x10)')
plt.show()

def opening_recommendations(player_id,ete, k=5):
    """
    Rekomendasi Pembukaan Catur untuk Pemain berdasarkan preferensi atau data yang ada.

    Parameter:
    ---
    player_id : tipe data string (str)
                ID Pemain
    player_data : tipe data pd.DataFrame (object)
                  Data yang berisi preferensi atau riwayat pembukaan pemain
    opening_list : tipe data list (list)
                   Daftar pembukaan catur yang tersedia
    k : tipe data integer (int)
        Banyaknya jumlah rekomendasi yang diberikan
    ---

    Pada fungsi ini, kita memberikan rekomendasi pembukaan catur untuk pemain
    berdasarkan preferensi atau data yang ada.
    """
    # Filter data untuk pemain tertentu
    player_preferences = opening_used[opening_used['player_id'] == player_id]

    if player_preferences.empty:
        raise ValueError(f"Player '{player_id}' not found in the dataset")

    # Ambil daftar pembukaan yang sering digunakan oleh pemain
    player_openings = opening_used['opening_archetype'].unique()

    # Rekomendasi pembukaan yang belum digunakan oleh pemain
    recommended_openings = [opening for opening in opening_archetype if opening not in player_openings]

    # Jika tidak ada rekomendasi, berikan pesan
    if not recommended_openings:
        print(f"\nTidak ada rekomendasi pembukaan untuk player '{player_id}'.")
        return []

    # Mengembalikan daftar rekomendasi pembukaan
    return recommended_openings[:k]

# Contoh rekomendasi untuk pemain "--jim--"
player_id = '--jim--'
print(f"\nRekomendasi opening catur untuk user '{player_id}':")
recommended_openings = opening_recommendations(player_id)
for opening in recommended_openings:
    print(opening)

"""# Model Development with Collaborative Filtering

## Encode User dan Opening
"""

chess_data = opening_used.copy()
chess_data.head()

# Encode user_id
user_ids = opening_used['player_id'].unique().tolist()
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}

# Encode opening_archetype
opening_ids = opening_used['opening_archetype'].unique().tolist()
opening_to_opening_encoded = {x: i for i, x in enumerate(opening_ids)}
opening_encoded_to_opening = {i: x for i, x in enumerate(opening_ids)}

# Mapping ke dataset
chess_data['user'] = chess_data['player_id'].map(user_to_user_encoded)
chess_data['opening'] = chess_data['opening_archetype'].map(opening_to_opening_encoded)

"""## Normalisasi Rating"""

# Normalisasi times_used ke skala 0-1
min_rating = min(chess_data['times_used'])
max_rating = max(chess_data['times_used'])
chess_data['rating'] = chess_data['times_used'].apply(lambda x: (x - min_rating) / (max_rating - min_rating))

"""## Membagi Data untuk Training dan Validasi"""

# Acak dataset
chess_data = chess_data.sample(frac=1, random_state=42)

# Membagi data
x = chess_data[['user', 'opening']].values
y = chess_data['rating'].values

train_indices = int(0.8 * len(chess_data))
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

# Tampilkan hasil
print("Data Training:")
print(x_train, y_train)

print("\nData Validasi:")
print(x_val, y_val)

"""## Proses Training"""

class ChessRecommenderNet(tf_lib.keras.Model):
    def __init__(self, num_users, num_openings, embedding_size, **kwargs):
        super(ChessRecommenderNet, self).__init__(**kwargs)
        self.num_users = num_users
        self.num_openings = num_openings
        self.embedding_size = embedding_size
        self.user_embedding = layers.Embedding(
            num_users,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.user_bias = layers.Embedding(num_users, 1)
        self.opening_embedding = layers.Embedding(
            num_openings,
            embedding_size,
            embeddings_initializer='he_normal',
            embeddings_regularizer=keras.regularizers.l2(1e-6)
        )
        self.opening_bias = layers.Embedding(num_openings, 1)

    def call(self, inputs):
        user_vector = self.user_embedding(inputs[:, 0])
        user_bias = self.user_bias(inputs[:, 0])
        opening_vector = self.opening_embedding(inputs[:, 1])
        opening_bias = self.opening_bias(inputs[:, 1])

        dot_user_opening = tf_lib.tensordot(user_vector, opening_vector, 2)
        x = dot_user_opening + user_bias + opening_bias

        return tf_lib.nn.sigmoid(x)

# Inisialisasi model
num_users = len(user_to_user_encoded)
num_openings = len(opening_to_opening_encoded)
model = ChessRecommenderNet(num_users, num_openings, 50)

# Compile model
model.compile(
    loss=tf_lib.keras.losses.BinaryCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf_lib.keras.metrics.RootMeanSquaredError()]
)

# Training model
history = model.fit(
    x=x_train,
    y=y_train,
    batch_size=64,
    epochs=100,
    validation_data=(x_val, y_val)
)

# Plot RMSE
plt.plot(history.history['root_mean_squared_error'], label='Train RMSE')
plt.plot(history.history['val_root_mean_squared_error'], label='Validation RMSE')
plt.title('Model Metrics')
plt.ylabel('RMSE')
plt.xlabel('Epoch')
plt.legend()
plt.show()

def get_opening_recommendations(user_id, top_k=5):
    # Daftar opening yang belum pernah digunakan oleh pengguna
    opening_used_by_user = chess_data[chess_data['user'] == user_to_user_encoded[user_id]]['opening']
    opening_not_used = [opening for opening in range(num_openings) if opening not in opening_used_by_user]

    # Buat input untuk model
    user_encoder = user_to_user_encoded[user_id]
    user_opening_array = np.array([[user_encoder, opening] for opening in opening_not_used])

    # Prediksi rating
    ratings = model.predict(user_opening_array).flatten()
    top_ratings_indices = ratings.argsort()[-top_k:][::-1]

    # Mendapatkan rekomendasi
    recommended_opening_ids = [opening_not_used[i] for i in top_ratings_indices]
    recommended_openings = [opening_encoded_to_opening[opening_id] for opening_id in recommended_opening_ids]

    print(f"Rekomendasi opening catur untuk user {user_id}:")
    for opening in recommended_openings:
        print(opening)

# Contoh penggunaan
get_opening_recommendations('--jim--')

